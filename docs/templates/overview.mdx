---
title: 'Template Overview'
description: 'Choose the right template for your project'
---

## Available Templates

create-llm provides 4 pre-configured templates optimized for different use cases:

<CardGroup cols={2}>
  <Card title="NANO" icon="atom" href="/templates/nano">
    **1M parameters** - Perfect for learning and quick experiments
  </Card>
  <Card title="TINY" icon="cube" href="/templates/tiny">
    **6M parameters** - Great for prototyping and small projects
  </Card>
  <Card title="SMALL" icon="box" href="/templates/small">
    **100M parameters** - Production-ready for real applications
  </Card>
  <Card title="BASE" icon="boxes-stacked" href="/templates/base">
    **1B parameters** - Research-grade high-quality models
  </Card>
</CardGroup>

## Comparison Table

| Template | Parameters | Hardware | Training Time | Data Needed | Use Case |
|----------|-----------|----------|---------------|-------------|----------|
| **NANO** | ~1M | Any CPU (2GB RAM) | 1-2 minutes | 100+ examples | Learning, testing |
| **TINY** | ~6M | CPU/Basic GPU (4GB) | 5-15 minutes | 1,000+ examples | Prototypes |
| **SMALL** | ~100M | RTX 3060+ (12GB) | 1-3 hours | 10,000+ examples | Production |
| **BASE** | ~1B | A100/Multi-GPU | 1-3 days | 100,000+ examples | Research |

## How to Choose

<Steps>
  <Step title="Consider Your Goal">
    - **Learning?** → Start with NANO
    - **Prototype?** → Use TINY
    - **Production app?** → Choose SMALL
    - **Research?** → Go with BASE
  </Step>

  <Step title="Check Your Data">
    - **< 1,000 examples** → NANO only
    - **1K-10K examples** → TINY
    - **10K-100K examples** → SMALL
    - **100K+ examples** → BASE
  </Step>

  <Step title="Assess Your Hardware">
    - **CPU only** → NANO or TINY
    - **Consumer GPU (8-12GB)** → SMALL
    - **Professional GPU (40GB+)** → BASE
  </Step>
</Steps>

## Template Architecture

All templates use the GPT architecture with different configurations:

```python
# NANO Configuration
{
  "layers": 3,
  "heads": 4,
  "dim": 128,
  "vocab_size": 5000,
  "max_length": 256
}

# TINY Configuration
{
  "layers": 4,
  "heads": 4,
  "dim": 256,
  "vocab_size": 10000,
  "max_length": 512
}

# SMALL Configuration
{
  "layers": 12,
  "heads": 12,
  "dim": 768,
  "vocab_size": 50000,
  "max_length": 1024
}

# BASE Configuration
{
  "layers": 24,
  "heads": 16,
  "dim": 1024,
  "vocab_size": 50000,
  "max_length": 2048
}
```

## Creating a Project

<Tabs>
  <Tab title="Interactive">
    ```bash
    npx create-llm
    # Follow the prompts to select template
    ```
  </Tab>

  <Tab title="Direct">
    ```bash
    # Specify template directly
    npx create-llm my-project --template nano
    npx create-llm my-project --template tiny
    npx create-llm my-project --template small
    npx create-llm my-project --template base
    ```
  </Tab>
</Tabs>

## Custom Templates

Want to create your own template? Use the `custom` option:

```bash
npx create-llm my-project --template custom
```

Then edit `llm.config.js` to customize:

```javascript
module.exports = {
  model: {
    type: 'gpt',
    size: 'custom',
    layers: 8,        // Your custom layer count
    heads: 8,         // Your custom head count
    dim: 512,         // Your custom dimension
    vocab_size: 20000,
    max_length: 1024,
  },
  // ... rest of config
};
```

## Next Steps

<CardGroup cols={2}>
  <Card title="NANO Template" icon="atom" href="/templates/nano">
    Learn about the NANO template
  </Card>
  <Card title="Training Tips" icon="lightbulb" href="/guides/training-tips">
    Optimize your training
  </Card>
</CardGroup>
